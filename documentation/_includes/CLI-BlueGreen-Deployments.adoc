:sectnums:
:sectnumlevels: 2
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

:toc:

= CLI: Blue Green Deployments

In this unit, we will use a simple PHP based application to simulate and observe an application deployment, scaling adjustments and updates under different scenarios.  Topics covered will include: 

  . Environment Variables,
  . Secrets,
  . Application Scaling,
  . Rollbacks,
  . Deployment Strategies, and
  . Blue Green Updates using Routes

Take a moment to review the source for this exercise.  It is NOT very complicated.

*Source Code:* link:https://github.com/xtophd/OCP-Workshop/blob/master/src/bluegreen/index.php[index.php]

This application uses a single code base to execute 2 different activities.  If left unconfigured, the application is "Idle".  Once configured the application is either a "Worker" or a "Watcher".  So the basic premise of this exercise is to deploy the same code base in 2 different Openshift applications and then configure one as a "Worker" and the other as a "Watcher".

Let's get started by repeating the 6 typical steps of deploying and application:

  . *Credentials:* oc login
  . *Create a Project:* oc new project 
  . *Deploy an Image:* oc new-app
  . *Expose a Route:* oc expose
  . *Modify the Project, Build or Deployment*
  . *Validation*

== Initial Deployment of Blue Green

=== Credentials

NOTE: If you are continuing work from previous workshop exercises, chances are you can skip right to the next section.

Ensure you are signed on to the `master.example.com` host as the user `root`.  Also ensure that your openshift crendential is `admin`.

.[root@workstation ~]#
----
ssh master.example.com
----

.[root@master ~]# 
----
oc whoami
----

.Your output should look like this
[source,indent=4]
----
admin                                                                                 
----

If you are NOT signed in as `admin`, proceed to sign-on to Openshift.

.Key-Values for Login
[horizontal]
*Username*:: admin
*Password*:: redhat

.[root@master ~]#
----
oc login -u admin
----

=== Create a Project

.[root@master ~]#
----
oc new-project bluegreen --description="Workshop Blue Green Exercise" --display-name="Blue Green"
----

=== Deploy an Image

As mentioned, we are going to create 2 applications using the same source.  One will be called "watcher" and the other "worker"

.[root@master ~]#
----
oc new-app registry.access.redhat.com/rhscl/php-71-rhel7~https://github.com/xtophd/OCP-Workshop --context-dir=/src/bluegreen --name=watcher

oc new-app registry.access.redhat.com/rhscl/php-71-rhel7~https://github.com/xtophd/OCP-Workshop --context-dir=/src/bluegreen --name=worker
----

We will pause here until the applications are built.  

.[root@master ~]#
----
oc logs -f bc/watcher
----

At this point we've deployed 2 applications which do nothing and report themselves as "Idle".

=== Expose a Route

.[root@master ~]#
----
oc expose service watcher --hostname=watcher.cloud.example.com

oc expose service worker  --hostname=worker.cloud.example.com
----

== Environment Variables

Openshift environment variables are a means to pass key/value pairs from the underlying host to the processess in the container.  Variables can provide configuration data, credentials and more.

=== Add Env Vars to Build Configs

.[root@master ~]#
----
oc env dc/worker myMode=worker myColor=blue

oc logs -f dc/worker

curl http://worker.cloud.example.com
----

.[root@master ~]#
----
oc env dc/watcher myMode=watcher myRoute=http://worker.cloud.example.com

oc logs -f dc/watcher

curl http://watcher.cloud.example.com

lynx -dump http://watcher.cloud.example.com
----

=== Scale up 'worker' pods

.[root@master ~]#
----
oc scale --replicas=3 dc/worker
----

.[root@master ~]#
----
oc get pods -o wide
----

.[root@master ~]#
----
lynx -dump http://watcher.cloud.example.com
----

=== Change Env Vars in Build Configs

.[root@master ~]#
----
oc env dc/worker myColor=green
----

.[root@master ~]#
----
watch lynx -dump http://watcher.cloud.example.com
----

.[root@master ~]#
----
oc scale --replicas=10 dc/worker
----

.[root@master ~]#
----
watch lynx -dump http://watcher.cloud.example.com
----

.[root@master ~]#
----
oc env dc/worker myColor=blue
----

.[root@master ~]#
----
watch lynx -dump http://watcher.cloud.example.com
----

== Secrets

Secrets decouple sensitive content from the pods that use it.  They can be mounted into containers using a volume plug-in or used by the system to perform actions on behalf of a pod. 

=== Create a Secret

=== Add Secret to Build Configs

=== Consumig Secrets in Pods

== Deployments

=== View Available Revisions

Retreve general revision history

.[root@master ~]#
----
oc rollout history dc/worker
----

=== Rollbacks

==== View Revision History

.[root@master ~]#
----
oc rollout history dc/worker --revision=2
----

==== View Details of Secific Revision

.[root@master ~]#
----
oc rollout history dc/worker --revision=2
----

==== Rolling Back Changes

Here is an example of rolling back to the last revision

.[root@master ~]#
----
oc rollback dc/worker
----

Here is an example of rolling back to a specific revision

.[root@master ~]#
----
oc rollback dc/worker --revision=2
----

== Strategies

A deployment strategy is an algorithym which is implemented when changing or upgrading an application. The goal is to invoke change whilst reducing downtime or disruption to the end user.

There are 3 fundamental strategies for rollouts:

  . *Rolling*: slowly replaces previous version of an application with instances of the new version.  Uses parameters like *masSurge* and *maxUnavailable* (among others) to control rolling behaviour. Use when: you don't want downtime, app supports old code and new code coexisting for a brief period.
  . *Recreate*: scales down previous deployment to zero, then scales up the new deployment.  Uses additional pre/mid/post-lifecycle hooks to customize.  Use when: outside tasks are necessart (ie: migrations), incompatabilities between versions, volumes are used which cannot be shared.
  . *Custom*: provide your own deployment behaviour.  

The WebUI provides a relatively simple interface to modifying a strategy and it's accompanying parameters.  From the command-line, we are currently left with `oc edit` or `oc patch`

=== Scale Up Number of Workers

To get a better sense of how deployments update, let us add a few more pods to the deployment

.[root@master ~]#
----
oc scale --replicas=10 dc/worker
----

=== Watch a Rolling Update

To set up the environment for this exercise, first we want our exisiting worker app to be configure to `blue`.

.[root@master ~]#
----
oc env dc/worker myMode=worker myColor=blue
----

The default strategy is "rolling", so no configuration is required at this point.

As you hopefully have noticed by now, we can trigger a rollout simply by changing an environment variable.

.[root@master ~]#
----
oc env dc/worker myMode=worker myColor=green
----

Within a minute or so, you should see the pods changing their configuration from blue to green.  In particular, what you want to take notice of is that there is an over lab of time when both blue and green pods are running simultaneously.  This is expected behaviour from a 'rolling' deployment.


=== Watch a Recreate Update

To set up the environment for this exercise, first we want our exisiting worker app to be `blue`.

.[root@master ~]#
----
oc env dc/worker myMode=worker myColor=blue
----

Wait until all pods are 'blue' before proceeding.

Now you will reconfigure the deployment strategy to "Recreate".

.[root@master ~]#
----
oc patch dc/worker --patch '{"spec":{"strategy":{"type":"Recreate"}}}'
----

Now, we can trigger a rollout simply by changing an environment variable.

.[root@master ~]#
----
oc env dc/worker myMode=worker myColor=green
----

Within a minute or so, you should see the pods (or more accurately the number of replicas) scale down to zero, and then scale back up with the new 'green' configuration.  This is expected behaviour from a 'recreate' deployment.


=== Watch a Blue Green Update

==== Scale Down Number of Workers

To prevent any resource contention problems in our limited workshop environment, scale down the number of replicas to 5.

.[root@master ~]#
----
oc scale --replicas=5 dc/worker
----

==== Deploy 3rd Application

At this point, you have dpeloyed 2 applications based on the same code base, one is configured as a `watched` and the other as a `worker`.  For the blue-green model to work, we need a parallel set of pods running with the new configuration.  

Deploy another app and configure it as `green`.  To shortend the individual steps required, here is a consolidated `oc new-app` command  line that deploys the application with it's `green` environment configuration.

.[root@master ~]#
----
oc new-app registry.access.redhat.com/rhscl/php-71-rhel7~https://github.com/xtophd/OCP-Workshop --context-dir=/src/bluegreen --name=worker-v2 -e myMode=worker -e myColor=green
----

.[root@master ~]#
----
oc logs -f bc/worker-v2
----

Wait until the deployment is complete.

==== Scale Up

To match the scale of the existing `worker` application, we nede to scale up `worker-v2`

.[root@master ~]#
----
oc scale --replicas=5 dc/worker-v2
----

==== Switch the Exposed Route

Finally, the last step is to switch the service which acts as the ingres for the current exposed route for `worker`.

.[root@master ~]#
----
oc patch route worker --patch '{"spec":{"to":{"name":"worker-v2"}}}'
----

Notice how fast and simple the app switches from old to new.  If someone deteremines there is a problem with the new application, you can just as easily switch back.

== EXTRA STUFF

=== List variables for a POD

oc set env pod/p1 --list

=== Trigger a fresh build after source edit

oc start-build bc/worker
oc logs -f bc/worker

[discrete]
== End of Unit

link:../OCP-Workshop.adoc[Return to TOC]

////
Always end files with a blank line to avoid include problems.
////
